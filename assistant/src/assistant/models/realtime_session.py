# coding: utf-8

"""
OpenAI API

The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.

The version of the OpenAPI document: 2.3.0
Generated by OpenAPI Generator (https://openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json


from pydantic import BaseModel, ConfigDict, Field, StrictFloat, StrictInt, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional, Union
from assistant.models.realtime_response_create_params_max_response_output_tokens import (
    RealtimeResponseCreateParamsMaxResponseOutputTokens,
)
from assistant.models.realtime_response_create_params_tools_inner import RealtimeResponseCreateParamsToolsInner
from assistant.models.realtime_session_input_audio_noise_reduction import RealtimeSessionInputAudioNoiseReduction
from assistant.models.realtime_session_input_audio_transcription import RealtimeSessionInputAudioTranscription
from assistant.models.realtime_session_turn_detection import RealtimeSessionTurnDetection
from assistant.models.voice_ids_shared import VoiceIdsShared

try:
    from typing import Self
except ImportError:
    from typing_extensions import Self


class RealtimeSession(BaseModel):
    """
    Realtime session object configuration.
    """  # noqa: E501

    id: Optional[StrictStr] = Field(
        default=None, description="Unique identifier for the session that looks like `sess_1234567890abcdef`. "
    )
    modalities: Optional[List[StrictStr]] = Field(
        default=None,
        description='The set of modalities the model can respond with. To disable audio, set this to ["text"]. ',
    )
    model: Optional[StrictStr] = Field(default=None, description="The Realtime model used for this session. ")
    instructions: Optional[StrictStr] = Field(
        default=None,
        description='The default system instructions (i.e. system message) prepended to model  calls. This field allows the client to guide the model on desired  responses. The model can be instructed on response content and format,  (e.g. "be extremely succinct", "act friendly", "here are examples of good  responses") and on audio behavior (e.g. "talk quickly", "inject emotion  into your voice", "laugh frequently"). The instructions are not guaranteed  to be followed by the model, but they provide guidance to the model on the desired behavior.  Note that the server sets default instructions which will be used if this  field is not set and are visible in the `session.created` event at the  start of the session. ',
    )
    voice: Optional[VoiceIdsShared] = None
    input_audio_format: Optional[StrictStr] = Field(
        default="pcm16",
        description="The format of input audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, input audio must be 16-bit PCM at a 24kHz sample rate,  single channel (mono), and little-endian byte order. ",
    )
    output_audio_format: Optional[StrictStr] = Field(
        default="pcm16",
        description="The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`. For `pcm16`, output audio is sampled at a rate of 24kHz. ",
    )
    input_audio_transcription: Optional[RealtimeSessionInputAudioTranscription] = None
    turn_detection: Optional[RealtimeSessionTurnDetection] = None
    input_audio_noise_reduction: Optional[RealtimeSessionInputAudioNoiseReduction] = None
    tools: Optional[List[RealtimeResponseCreateParamsToolsInner]] = Field(
        default=None, description="Tools (functions) available to the model."
    )
    tool_choice: Optional[StrictStr] = Field(
        default="auto",
        description="How the model chooses tools. Options are `auto`, `none`, `required`, or  specify a function. ",
    )
    temperature: Optional[Union[StrictFloat, StrictInt]] = Field(
        default=0.8,
        description="Sampling temperature for the model, limited to [0.6, 1.2]. For audio models a temperature of 0.8 is highly recommended for best performance. ",
    )
    max_response_output_tokens: Optional[RealtimeResponseCreateParamsMaxResponseOutputTokens] = None
    __properties: ClassVar[List[str]] = [
        "id",
        "modalities",
        "model",
        "instructions",
        "voice",
        "input_audio_format",
        "output_audio_format",
        "input_audio_transcription",
        "turn_detection",
        "input_audio_noise_reduction",
        "tools",
        "tool_choice",
        "temperature",
        "max_response_output_tokens",
    ]

    @field_validator("modalities")
    def modalities_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        for i in value:
            if i not in (
                "text",
                "audio",
            ):
                raise ValueError("each list item must be one of ('text', 'audio')")
        return value

    @field_validator("model")
    def model_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in (
            "gpt-4o-realtime-preview",
            "gpt-4o-realtime-preview-2024-10-01",
            "gpt-4o-realtime-preview-2024-12-17",
            "gpt-4o-mini-realtime-preview",
            "gpt-4o-mini-realtime-preview-2024-12-17",
        ):
            raise ValueError(
                "must be one of enum values ('gpt-4o-realtime-preview', 'gpt-4o-realtime-preview-2024-10-01', 'gpt-4o-realtime-preview-2024-12-17', 'gpt-4o-mini-realtime-preview', 'gpt-4o-mini-realtime-preview-2024-12-17')"
            )
        return value

    @field_validator("input_audio_format")
    def input_audio_format_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in (
            "pcm16",
            "g711_ulaw",
            "g711_alaw",
        ):
            raise ValueError("must be one of enum values ('pcm16', 'g711_ulaw', 'g711_alaw')")
        return value

    @field_validator("output_audio_format")
    def output_audio_format_validate_enum(cls, value):
        """Validates the enum"""
        if value is None:
            return value

        if value not in (
            "pcm16",
            "g711_ulaw",
            "g711_alaw",
        ):
            raise ValueError("must be one of enum values ('pcm16', 'g711_ulaw', 'g711_alaw')")
        return value

    model_config = {
        "populate_by_name": True,
        "validate_assignment": True,
        "protected_namespaces": (),
    }

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Create an instance of RealtimeSession from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        _dict = self.model_dump(
            by_alias=True,
            exclude={},
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of voice
        if self.voice:
            _dict["voice"] = self.voice.to_dict()
        # override the default output from pydantic by calling `to_dict()` of input_audio_transcription
        if self.input_audio_transcription:
            _dict["input_audio_transcription"] = self.input_audio_transcription.to_dict()
        # override the default output from pydantic by calling `to_dict()` of turn_detection
        if self.turn_detection:
            _dict["turn_detection"] = self.turn_detection.to_dict()
        # override the default output from pydantic by calling `to_dict()` of input_audio_noise_reduction
        if self.input_audio_noise_reduction:
            _dict["input_audio_noise_reduction"] = self.input_audio_noise_reduction.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in tools (list)
        _items = []
        if self.tools:
            for _item in self.tools:
                if _item:
                    _items.append(_item.to_dict())
            _dict["tools"] = _items
        # override the default output from pydantic by calling `to_dict()` of max_response_output_tokens
        if self.max_response_output_tokens:
            _dict["max_response_output_tokens"] = self.max_response_output_tokens.to_dict()
        return _dict

    @classmethod
    def from_dict(cls, obj: Dict) -> Self:
        """Create an instance of RealtimeSession from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "id": obj.get("id"),
                "modalities": obj.get("modalities"),
                "model": obj.get("model"),
                "instructions": obj.get("instructions"),
                "voice": VoiceIdsShared.from_dict(obj.get("voice")) if obj.get("voice") is not None else None,
                "input_audio_format": (
                    obj.get("input_audio_format") if obj.get("input_audio_format") is not None else "pcm16"
                ),
                "output_audio_format": (
                    obj.get("output_audio_format") if obj.get("output_audio_format") is not None else "pcm16"
                ),
                "input_audio_transcription": (
                    RealtimeSessionInputAudioTranscription.from_dict(obj.get("input_audio_transcription"))
                    if obj.get("input_audio_transcription") is not None
                    else None
                ),
                "turn_detection": (
                    RealtimeSessionTurnDetection.from_dict(obj.get("turn_detection"))
                    if obj.get("turn_detection") is not None
                    else None
                ),
                "input_audio_noise_reduction": (
                    RealtimeSessionInputAudioNoiseReduction.from_dict(obj.get("input_audio_noise_reduction"))
                    if obj.get("input_audio_noise_reduction") is not None
                    else None
                ),
                "tools": (
                    [RealtimeResponseCreateParamsToolsInner.from_dict(_item) for _item in obj.get("tools")]
                    if obj.get("tools") is not None
                    else None
                ),
                "tool_choice": obj.get("tool_choice") if obj.get("tool_choice") is not None else "auto",
                "temperature": obj.get("temperature") if obj.get("temperature") is not None else 0.8,
                "max_response_output_tokens": (
                    RealtimeResponseCreateParamsMaxResponseOutputTokens.from_dict(obj.get("max_response_output_tokens"))
                    if obj.get("max_response_output_tokens") is not None
                    else None
                ),
            }
        )
        return _obj
